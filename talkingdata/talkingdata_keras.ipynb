{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/callum/anaconda2/envs/dl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Input, Embedding, SpatialDropout1D, concatenate, Merge\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import cyclic\n",
    "os.environ['OMP_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set the path of the data\n",
    "# PATH = \"~/.kaggle/competitions/talkingdata-adtracking-fraud-detection\"\n",
    "PATH = \"../data/talkingdata\"\n",
    "SCRATCH_PATH = \"/scratch/brown/g1082124/talkingdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "#train = pd.read_csv(PATH + \"/train_1_4.csv\")\n",
    "train = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_vars = [\"app\", \"device\", \"os\", \"channel\", \"hour\", \"day\", \"wday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Method for getting data in a format that keras can work worth\n",
    "def getKerasData(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        #'ip': np.array(dataset.ip),\n",
    "        'device': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'channel': np.array(dataset.channel),\n",
    "        'hour': np.array(dataset.hour),\n",
    "        'day': np.array(dataset.day),\n",
    "        'wday': np.array(dataset.wday),\n",
    "        'qty': np.array(dataset.wday),\n",
    "        'ip_app_count': np.array(dataset.ip_app_count),\n",
    "        'ip_app_os_count': np.array(dataset.ip_app_os_count),\n",
    "    }\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Method for changing the train dataset, e.g. changing which quarter of the set to use\n",
    "def changeDataset(fname):\n",
    "    #del train#, X_train, y_train, X_valid, y_valid; gc.collect()\n",
    "    global X_train, y_train, X_valid, y_valid, idx_split\n",
    "    train = pd.read_csv(PATH + \"/\" + fname)\n",
    "    \n",
    "    idx_split = int(len(train) * .75)\n",
    "\n",
    "    X_train = getKerasData(train.iloc[:idx_split])\n",
    "    y_train = train[\"is_attributed\"].iloc[:idx_split].values\n",
    "\n",
    "    X_valid = getKerasData(train.iloc[idx_split:])\n",
    "    y_valid = train[\"is_attributed\"].iloc[idx_split:].values\n",
    "    del train\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#changeDataset('train_3_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On to the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get Nums of Unique Values (max value + 1)\n",
    "#max_ip = 333168\n",
    "max_app = 730\n",
    "max_device = 3799\n",
    "max_os = 856\n",
    "max_channel = 202\n",
    "max_hour = 24\n",
    "max_day = 5\n",
    "max_wday = 5\n",
    "max_qty = 44260\n",
    "max_c1 = 220744\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the inputs and embedding layers\n",
    "emb_szs = emb_n = 50\n",
    "dense_szs = 1024\n",
    "\n",
    "in_app = Input(shape=[1], name=\"app\")\n",
    "emb_app = Embedding(max_app, emb_szs)(in_app)\n",
    "#in_ip = Input(shape=[1], name=\"ip\")\n",
    "#emb_ip = Embedding(max_ip, emb_szs)(in_ip)\n",
    "in_device = Input(shape=[1], name=\"device\")\n",
    "emb_device = Embedding(max_device, 70)(in_device)\n",
    "in_os = Input(shape=[1], name=\"os\")\n",
    "emb_os = Embedding(max_os, emb_szs)(in_os)\n",
    "in_channel = Input(shape=[1], name=\"channel\")\n",
    "emb_channel = Embedding(max_channel, emb_szs)(in_channel)\n",
    "in_hour = Input(shape=[1], name=\"hour\")\n",
    "emb_hour = Embedding(max_hour, 16)(in_hour)\n",
    "in_day = Input(shape=[1], name=\"day\")\n",
    "emb_day = Embedding(max_day, 16)(in_day)\n",
    "in_wday = Input(shape=[1], name=\"wday\")\n",
    "emb_wday = Embedding(max_wday, 16)(in_wday)\n",
    "in_qty = Input(shape=[1], name=\"qty\")\n",
    "emb_qty = Embedding(max_qty, emb_szs)(in_qty)\n",
    "in_c1 = Input(shape=[1], name=\"ip_app_count\")\n",
    "emb_c1 = Embedding(max_c1, emb_szs)(in_c1)\n",
    "in_c2 = Input(shape=[1], name=\"ip_app_os_count\")\n",
    "emb_c2 = Embedding(max_c1, emb_szs)(in_c2)\n",
    "\n",
    "#embs = concatenate([(emb_app), (emb_ip), (emb_device), (emb_os), (emb_channel)])\n",
    "embs = concatenate([(emb_app), (emb_device), (emb_os), (emb_channel), (emb_hour),\n",
    "                   (emb_day), (emb_wday), (emb_qty), (emb_c1), (emb_c2)])\n",
    "\n",
    "# Now turn those into dense layers\n",
    "s_dout = SpatialDropout1D(0.4)(embs)\n",
    "x = Flatten()(s_dout)\n",
    "x = Dropout(0.4)(Dense(dense_szs, activation=\"relu\")(x))\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(Dense(dense_szs, activation=\"relu\")(x))\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "#model = Model(inputs=[in_app,in_channel,in_device,in_os,in_ip], outputs=output)\n",
    "model = Model(inputs=[in_app,in_channel,in_device,in_os,in_hour,\n",
    "                     in_day,in_wday,in_qty,in_c1,in_c2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Learning Rate Decay\n",
    "bs = 70000\n",
    "epochs = 1\n",
    "# exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "# steps = int(idx_split / bs) * epochs\n",
    "# lr_init, lr_fin = 0.003, 0.0002\n",
    "# lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "#optimizer_adam = Adam(lr=0.0005, decay=lr_decay)\n",
    "optimizer_adam = Adam(lr=.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clr = cyclic.CyclicLR(base_lr=.0001, max_lr=.001, step_size=2000, mode=\"triangular2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model.summary()\n",
    "model.load_weights('../models/talkingdata_4epoch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ROC Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class roc_callback(keras.callbacks.Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x, batch_size=bs, verbose=2)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        #roc = 1\n",
    "        y_pred_val = self.model.predict(self.x_val, batch_size=bs, verbose=2)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#About .02% of the dataset is positive, class weights make up for that\n",
    "#class_weight = {0:.0002,1:.9998}\n",
    "class_weight = {0: .0015, 1:.99}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on split 2\n",
      "Train on 34669479 samples, validate on 11556494 samples\n",
      "Epoch 1/1\n",
      "34669479/34669479 [==============================] - 308s 9us/step - loss: 6.3714e-04 - acc: 0.9376 - val_loss: 0.2173 - val_acc: 0.9299\n",
      "roc-auc: 0.9835 - roc-auc_val: 0.9766                                                                                                    \n",
      "Working on split 1\n",
      "Train on 34669479 samples, validate on 11556493 samples\n",
      "Epoch 1/1\n",
      "34669479/34669479 [==============================] - 305s 9us/step - loss: 7.7020e-04 - acc: 0.9259 - val_loss: 0.2197 - val_acc: 0.9331\n",
      "roc-auc: 0.9771 - roc-auc_val: 0.9743                                                                                                    \n",
      "Working on split 3\n",
      "Train on 34669479 samples, validate on 11556493 samples\n",
      "Epoch 1/1\n",
      "34669479/34669479 [==============================] - 302s 9us/step - loss: 6.5449e-04 - acc: 0.9507 - val_loss: 0.1889 - val_acc: 0.9488\n",
      "roc-auc: 0.9809 - roc-auc_val: 0.9698                                                                                                    \n",
      "Working on split 4\n",
      "Train on 34669479 samples, validate on 11556494 samples\n",
      "Epoch 1/1\n",
      "34669479/34669479 [==============================] - 309s 9us/step - loss: 8.5068e-04 - acc: 0.9163 - val_loss: 0.1900 - val_acc: 0.9594\n",
      "roc-auc: 0.9747 - roc-auc_val: 0.9795                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "l = list(range(1, 5))\n",
    "shuffle(l)\n",
    "\n",
    "for n in l:\n",
    "    print('Working on split {}'.format(n))\n",
    "    changeDataset('train_{}_4.csv'.format(n))\n",
    "    callbacks=[roc_callback(training_data=(X_train, y_train),validation_data=(X_valid, y_valid)),\n",
    "          clr]\n",
    "    model.fit(X_train, y_train, batch_size=bs, validation_data=(X_valid, y_valid), epochs=epochs,\n",
    "          class_weight=class_weight, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34669479 samples, validate on 11556494 samples\n",
      "Epoch 1/1\n",
      "34669479/34669479 [==============================] - 306s 9us/step - loss: 9.4774e-04 - acc: 0.9060 - val_loss: 0.2186 - val_acc: 0.9509\n",
      "roc-auc: 0.9688 - roc-auc_val: 0.9721                                                                                                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb50c79c438>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=bs, validation_data=(X_valid, y_valid), epochs=epochs,\n",
    "          class_weight=class_weight, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/talkingdata_8epoch.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Confusion Matrix Visualization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795156240087143\n"
     ]
    }
   ],
   "source": [
    "# test = train.iloc[int(len(train)*.75):]\n",
    "# print(len(test))\n",
    "# X_test = getKerasData(test)\n",
    "# y_test = test[\"is_attributed\"].values\n",
    "# y_pred = model.predict(X_test, batch_size=bs, verbose=2)\n",
    "y_pred = model.predict(X_valid, batch_size=bs, verbose=2)\n",
    "roc = roc_auc_score(y_valid, y_pred)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_valid, np.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.95948078 0.04051922]\n",
      " [0.07610674 0.92389326]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, [\"nope\", \"yeet\"], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del X_train, X_valid, y_train, y_valid; gc.collect()\n",
    "test = pd.read_csv(PATH + \"/test_proc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame()\n",
    "submit['click_id'] = test['click_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = getKerasData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['is_attributed'] = model.predict(X_test, batch_size=bs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.176220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.194937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.072726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.078845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.071592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  is_attributed\n",
       "0         0       0.176220\n",
       "1         1       0.194937\n",
       "2         2       0.072726\n",
       "3         3       0.078845\n",
       "4         4       0.071592"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submits/talkingdata_7epoch_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('../models/talkingdata_7epoch.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
