{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/callum/anaconda2/envs/dl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Input, Embedding, SpatialDropout1D, concatenate, Merge\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set the path of the data\n",
    "# PATH = \"~/.kaggle/competitions/talkingdata-adtracking-fraud-detection\"\n",
    "PATH = \"../data/talkingdata\"\n",
    "SCRATCH_PATH = \"/scratch/brown/g1082124/talkingdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "#train = pd.read_csv(PATH + \"/train_1_4.csv\")\n",
    "train = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_vars = [\"app\", \"device\", \"os\", \"channel\", \"hour\", \"day\", \"wday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Method for getting data in a format that keras can work worth\n",
    "def getKerasData(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        #'ip': np.array(dataset.ip),\n",
    "        'device': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'channel': np.array(dataset.channel),\n",
    "        'hour': np.array(dataset.hour),\n",
    "        'day': np.array(dataset.day),\n",
    "        'wday': np.array(dataset.wday),\n",
    "        'qty': np.array(dataset.wday),\n",
    "        'ip_app_count': np.array(dataset.ip_app_count),\n",
    "        'ip_app_os_count': np.array(dataset.ip_app_os_count),\n",
    "    }\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Method for changing the train dataset, e.g. changing which quarter of the set to use\n",
    "def changeDataset(fname):\n",
    "    #del train#, X_train, y_train, X_valid, y_valid; gc.collect()\n",
    "    global X_train, y_train, X_valid, y_valid, idx_split\n",
    "    train = pd.read_csv(PATH + \"/\" + fname)\n",
    "    \n",
    "    idx_split = int(len(train) * .75)\n",
    "\n",
    "    X_train = getKerasData(train.iloc[:idx_split])\n",
    "    y_train = train[\"is_attributed\"].iloc[:idx_split].values\n",
    "\n",
    "    X_valid = getKerasData(train.iloc[idx_split:])\n",
    "    y_valid = train[\"is_attributed\"].iloc[idx_split:].values\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "changeDataset('train_1_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On to the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get Nums of Unique Values (max value + 1)\n",
    "#max_ip = 333168\n",
    "max_app = 730\n",
    "max_device = 3799\n",
    "max_os = 856\n",
    "max_channel = 202\n",
    "max_hour = 24\n",
    "max_day = 5\n",
    "max_wday = 5\n",
    "max_qty = 44260\n",
    "max_c1 = 220744\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the inputs and embedding layers\n",
    "emb_szs = emb_n = 50\n",
    "dense_szs = 1024\n",
    "\n",
    "in_app = Input(shape=[1], name=\"app\")\n",
    "emb_app = Embedding(max_app, emb_szs)(in_app)\n",
    "#in_ip = Input(shape=[1], name=\"ip\")\n",
    "#emb_ip = Embedding(max_ip, emb_szs)(in_ip)\n",
    "in_device = Input(shape=[1], name=\"device\")\n",
    "emb_device = Embedding(max_device, emb_szs)(in_device)\n",
    "in_os = Input(shape=[1], name=\"os\")\n",
    "emb_os = Embedding(max_os, emb_szs)(in_os)\n",
    "in_channel = Input(shape=[1], name=\"channel\")\n",
    "emb_channel = Embedding(max_channel, emb_szs)(in_channel)\n",
    "in_hour = Input(shape=[1], name=\"hour\")\n",
    "emb_hour = Embedding(max_hour, emb_szs)(in_hour)\n",
    "in_day = Input(shape=[1], name=\"day\")\n",
    "emb_day = Embedding(max_day, emb_szs)(in_day)\n",
    "in_wday = Input(shape=[1], name=\"wday\")\n",
    "emb_wday = Embedding(max_wday, emb_szs)(in_wday)\n",
    "in_qty = Input(shape=[1], name=\"qty\")\n",
    "emb_qty = Embedding(max_qty, emb_szs)(in_qty)\n",
    "in_c1 = Input(shape=[1], name=\"ip_app_count\")\n",
    "emb_c1 = Embedding(max_c1, emb_szs)(in_c1)\n",
    "in_c2 = Input(shape=[1], name=\"ip_app_os_count\")\n",
    "emb_c2 = Embedding(max_c1, emb_szs)(in_c2)\n",
    "\n",
    "#embs = concatenate([(emb_app), (emb_ip), (emb_device), (emb_os), (emb_channel)])\n",
    "embs = concatenate([(emb_app), (emb_device), (emb_os), (emb_channel), (emb_hour),\n",
    "                   (emb_day), (emb_wday), (emb_qty), (emb_c1), (emb_c2)])\n",
    "\n",
    "# Now turn those into dense layers\n",
    "s_dout = SpatialDropout1D(0.5)(embs)\n",
    "x = Flatten()(s_dout)\n",
    "x = Dropout(0.5)(Dense(dense_szs, activation=\"relu\")(x))\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(Dense(dense_szs, activation=\"relu\")(x))\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "#model = Model(inputs=[in_app,in_channel,in_device,in_os,in_ip], outputs=output)\n",
    "model = Model(inputs=[in_app,in_channel,in_device,in_os,in_hour,\n",
    "                     in_day,in_wday,in_qty,in_c1,in_c2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Learning Rate Decay\n",
    "bs = 50000\n",
    "epochs = 3\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(idx_split / bs) * epochs\n",
    "lr_init, lr_fin = 0.0008, 0.0001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=0.0008, decay=lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model.summary()\n",
    "model.load_weights('../models/talkingdata_2epoch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ROC Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class roc_callback(keras.callbacks.Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x, batch_size=bs, verbose=2)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        #roc = 1\n",
    "        y_pred_val = self.model.predict(self.x_val, batch_size=bs, verbose=2)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "callbacks=[roc_callback(training_data=(X_train, y_train),validation_data=(X_valid, y_valid))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#About .02% of the dataset is positive, class weights make up for that\n",
    "#class_weight = {0:.0002,1:.9998}\n",
    "class_weight = {0: .003, 1:.997}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on split 1\n",
      "Train on 34669479 samples, validate on 11556493 samples\n",
      "Epoch 1/3\n",
      "34669479/34669479 [==============================] - 319s 9us/step - loss: 0.0010 - acc: 0.9626 - val_loss: 0.1585 - val_acc: 0.9598\n",
      "roc-auc: 0.9783 - roc-auc_val: 0.9739                                                                                                    \n",
      "Epoch 2/3\n",
      "34669479/34669479 [==============================] - 317s 9us/step - loss: 0.0010 - acc: 0.9618 - val_loss: 0.1480 - val_acc: 0.9644\n",
      "roc-auc: 0.9798 - roc-auc_val: 0.9727                                                                                                    \n",
      "Epoch 3/3\n",
      "34669479/34669479 [==============================] - 316s 9us/step - loss: 9.8770e-04 - acc: 0.9612 - val_loss: 0.1418 - val_acc: 0.9676\n",
      "roc-auc: 0.9807 - roc-auc_val: 0.9729                                                                                                    \n",
      "Working on split 2\n",
      "Train on 34669479 samples, validate on 11556494 samples\n",
      "Epoch 1/3\n",
      "34669479/34669479 [==============================] - 317s 9us/step - loss: 9.0540e-04 - acc: 0.9709 - val_loss: 0.1252 - val_acc: 0.9707\n",
      "roc-auc: 0.978 - roc-auc_val: 0.9752                                                                                                    \n",
      "Epoch 2/3\n",
      "34669479/34669479 [==============================] - 317s 9us/step - loss: 8.8074e-04 - acc: 0.9699 - val_loss: 0.1296 - val_acc: 0.9696\n",
      "roc-auc: 0.9773 - roc-auc_val: 0.9751                                                                                                    \n",
      "Epoch 3/3\n",
      "34669479/34669479 [==============================] - 316s 9us/step - loss: 8.6967e-04 - acc: 0.9696 - val_loss: 0.1226 - val_acc: 0.9699\n",
      "roc-auc: 0.9768 - roc-auc_val: 0.9748                                                                                                    \n",
      "Working on split 4\n",
      "Train on 34669479 samples, validate on 11556494 samples\n",
      "Epoch 1/3\n",
      "34669479/34669479 [==============================] - 318s 9us/step - loss: 0.0012 - acc: 0.9617 - val_loss: 0.1025 - val_acc: 0.9813\n",
      "roc-auc: 0.9766 - roc-auc_val: 0.9753                                                                                                    \n",
      "Epoch 2/3\n",
      "34669479/34669479 [==============================] - 317s 9us/step - loss: 0.0012 - acc: 0.9622 - val_loss: 0.1004 - val_acc: 0.9815\n",
      "roc-auc: 0.976 - roc-auc_val: 0.9751                                                                                                    \n",
      "Epoch 3/3\n",
      "34669479/34669479 [==============================] - 317s 9us/step - loss: 0.0012 - acc: 0.9617 - val_loss: 0.1046 - val_acc: 0.9802\n",
      "roc-auc: 0.9759 - roc-auc_val: 0.9749                                                                                                    \n",
      "Working on split 3\n",
      "Train on 34669479 samples, validate on 11556493 samples\n",
      "Epoch 1/3\n",
      "34669479/34669479 [==============================] - 318s 9us/step - loss: 8.7841e-04 - acc: 0.9769 - val_loss: 0.1315 - val_acc: 0.9692\n",
      "roc-auc: 0.9758 - roc-auc_val: 0.9752                                                                                                    \n",
      "Epoch 2/3\n",
      "34669479/34669479 [==============================] - 318s 9us/step - loss: 8.6981e-04 - acc: 0.9770 - val_loss: 0.1250 - val_acc: 0.9707\n",
      "roc-auc: 0.9756 - roc-auc_val: 0.9752                                                                                                    \n",
      "Epoch 3/3\n",
      "34669479/34669479 [==============================] - 316s 9us/step - loss: 8.6197e-04 - acc: 0.9767 - val_loss: 0.1284 - val_acc: 0.9689\n",
      "roc-auc: 0.9755 - roc-auc_val: 0.9752                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "l = list(range(1, 5))\n",
    "shuffle(l)\n",
    "for n in l:\n",
    "    print('Working on split {}'.format(n))\n",
    "    changeDataset('train_{}_4.csv'.format(n))\n",
    "    model.fit(X_train, y_train, batch_size=bs, validation_data=(X_valid, y_valid), epochs=epochs,\n",
    "          class_weight=class_weight, callbacks=callbacks)\n",
    "#model.save_weights('../models/talkingdata_9epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/talkingdata_3epoch.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Confusion Matrix Visualization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Find Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751588005216886\n"
     ]
    }
   ],
   "source": [
    "# test = train.iloc[int(len(train)*.75):]\n",
    "# print(len(test))\n",
    "# X_test = getKerasData(test)\n",
    "# y_test = test[\"is_attributed\"].values\n",
    "# y_pred = model.predict(X_test, batch_size=bs, verbose=2)\n",
    "y_pred = model.predict(X_valid, batch_size=bs, verbose=2)\n",
    "roc = roc_auc_score(y_valid, y_pred)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_valid, np.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.96869435 0.03130565]\n",
      " [0.09971107 0.90028893]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, [\"nope\", \"yeet\"], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del train, X_train, X_valid, y_train, y_valid; gc.collect()\n",
    "test = pd.read_csv(PATH + \"/test_proc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame()\n",
    "submit['click_id'] = test['click_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = getKerasData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['is_attributed'] = model.predict(X_test, batch_size=bs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.131356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.124460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.043473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.056921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.036069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  is_attributed\n",
       "0         0       0.131356\n",
       "1         1       0.124460\n",
       "2         2       0.043473\n",
       "3         3       0.056921\n",
       "4         4       0.036069"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submits/talkingdata_2epoch_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
