{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/callum/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "Using cuDNN version 7005 on context None\n",
      "Preallocating 4861/6077 Mb (0.800000) on cuda0\n",
      "Mapped name None to device cuda0: GeForce GTX 1060 6GB (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import ZeroPadding2D, Conv2D\n",
    "from keras.layers import MaxPooling2D, BatchNormalization\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n",
    "\n",
    "def ConvBlock(layers, filters):\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1, 1)))\n",
    "            model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu'))  # Keras2\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "def FCBlock():\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.6))\n",
    "        #model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "ConvBlock(2, 64)\n",
    "ConvBlock(2, 128)\n",
    "ConvBlock(3, 256)\n",
    "ConvBlock(3, 512)\n",
    "ConvBlock(3, 512)\n",
    "\n",
    "model.add(Flatten())\n",
    "FCBlock()\n",
    "FCBlock()\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "model.load_weights('fastai/models/vgg16.h5')\n",
    "for layer in model.layers: layer.trainable=False\n",
    "model.pop()\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights('models/dogscats_ft_preprocessed2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout_indxs = [index for index,layer in enumerate(model.layers) \n",
    "                     if type(layer) is Dropout][::-1]\n",
    "fake_model = Sequential(model.layers[:35])\n",
    "#fake_model.add(BatchNormalization())\n",
    "fake_model.add(model.layers[35])\n",
    "fake_model.add(model.layers[36])\n",
    "#fake_model.add(BatchNormalization())\n",
    "fake_model.add(model.layers[-1])\n",
    "for layer in fake_model.layers[33:]:\n",
    "    layer.trainable=True\n",
    "#model.optimizer.lr.set_value(0.0001)\n",
    "fake_model.compile(optimizer=RMSprop(lr=.00001, rho=.7), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights('models/dogscats_ft_preprocessed2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers = model.layers[:31]\n",
    "conv_model = Sequential(conv_layers)\n",
    "fc_layers = model.layers[31:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='data/dogscats'\n",
    "train_path=path+\"/train\"\n",
    "valid_path=path+\"/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Get data\n",
    "from keras.preprocessing import image\n",
    "\n",
    "gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=.1, height_shift_range=.1,\n",
    "                              shear_range=.15, zoom_range=.1, channel_shift_range=10.,\n",
    "                              horizontal_flip=True)\n",
    "batch_size=24\n",
    "\n",
    "train_batches = gen.flow_from_directory(train_path, target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "val_batches = gen.flow_from_directory(valid_path, target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "classes = list(iter(train_batches.class_indices)) # get a list of all the class labels\n",
    "\n",
    "for c in train_batches.class_indices:\n",
    "    classes[train_batches.class_indices[c]] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = int(np.ceil(train_batches.samples/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.samples/batch_size))\n",
    "\n",
    "# trn_classes = train_batches.classes\n",
    "# val_classes = val_batches.classes\n",
    "# val_features = conv_model.predict_generator(val_batches, validation_steps)\n",
    "# trn_features = conv_model.predict_generator(train_batches, steps_per_epoch)\n",
    "# trn_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for layer in fake_model.layers[33:]:\n",
    "#    layer.trainable=True\n",
    "#model.optimizer.lr.set_value(0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit FC Layers\n",
    "#fake_model.load_weights('models/dogscats2.h5')\n",
    "#fc_model.fit(trn_features, trn_labels, epochs=1, batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "959/958 [==============================] - 280s 292ms/step - loss: 0.0982 - acc: 0.9900 - val_loss: 0.1648 - val_acc: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b4f96b9d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model\n",
    "#model.load_weights('models/dogscats2.h5')\n",
    "\n",
    "fake_model.fit_generator(train_batches, steps_per_epoch=int(np.ceil(train_batches.samples/batch_size)), epochs=1,\n",
    "                validation_data=val_batches, validation_steps=int(np.ceil(val_batches.samples/batch_size)))\n",
    "#model.fit_generator(train_batches, samples_per_epoch=train_batches.samples, epochs=1, validation_data=val_batches, validation_steps=val_batches.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_model.save_weights('models/dogscats_ft_preprocessed2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Examine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "import matplotlib.pyplot as plt\n",
    "#Use the plots helper function\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_batches = gen.flow_from_directory(train_path, target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get a few images and their true labels\n",
    "imgs, labels = next(sample_batches)\n",
    "indxs = np.argmax(labels, axis=1)\n",
    "indxs\n",
    "labels = [classes[indx] for indx in indxs]\n",
    "true_labels_dict = {\n",
    "    'c0': 'safe driving',\n",
    "    'c1': 'texting - right',\n",
    "    'c2': 'talking on the phone - right',\n",
    "    'c3': 'texting - left',\n",
    "    'c4': 'talking on the phone - left',\n",
    "    'c5': 'operating the radio',\n",
    "    'c6': 'drinking',\n",
    "    'c7': 'reaching behind',\n",
    "    'c8': 'hair and makeup',\n",
    "    'c9': 'talking to passenger',\n",
    "}\n",
    "true_labels = [true_labels_dict[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plots(imgs, titles=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '10001',\n",
       " '10002',\n",
       " '10003',\n",
       " '10004',\n",
       " '10005',\n",
       " '10006',\n",
       " '10007',\n",
       " '10008',\n",
       " '10009',\n",
       " '1001',\n",
       " '10010',\n",
       " '10011',\n",
       " '10012',\n",
       " '10013',\n",
       " '10014',\n",
       " '10015',\n",
       " '10016',\n",
       " '10017',\n",
       " '10018',\n",
       " '10019',\n",
       " '1002',\n",
       " '10020',\n",
       " '10021',\n",
       " '10022',\n",
       " '10023',\n",
       " '10024',\n",
       " '10025',\n",
       " '10026',\n",
       " '10027',\n",
       " '10028',\n",
       " '10029',\n",
       " '1003',\n",
       " '10030',\n",
       " '10031',\n",
       " '10032',\n",
       " '10033',\n",
       " '10034',\n",
       " '10035',\n",
       " '10036',\n",
       " '10037',\n",
       " '10038',\n",
       " '10039',\n",
       " '1004',\n",
       " '10040',\n",
       " '10041',\n",
       " '10042',\n",
       " '10043',\n",
       " '10044',\n",
       " '10045',\n",
       " '10046',\n",
       " '10047',\n",
       " '10048',\n",
       " '10049',\n",
       " '1005',\n",
       " '10050',\n",
       " '10051',\n",
       " '10052',\n",
       " '10053',\n",
       " '10054',\n",
       " '10055',\n",
       " '10056',\n",
       " '10057',\n",
       " '10058',\n",
       " '10059',\n",
       " '1006',\n",
       " '10060',\n",
       " '10061',\n",
       " '10062',\n",
       " '10063',\n",
       " '10064',\n",
       " '10065',\n",
       " '10066',\n",
       " '10067',\n",
       " '10068',\n",
       " '10069',\n",
       " '1007',\n",
       " '10070',\n",
       " '10071',\n",
       " '10072',\n",
       " '10073',\n",
       " '10074',\n",
       " '10075',\n",
       " '10076',\n",
       " '10077',\n",
       " '10078',\n",
       " '10079',\n",
       " '1008',\n",
       " '10080',\n",
       " '10081',\n",
       " '10082',\n",
       " '10083',\n",
       " '10084',\n",
       " '10085',\n",
       " '10086',\n",
       " '10087',\n",
       " '10088',\n",
       " '10089',\n",
       " '1009',\n",
       " '10090',\n",
       " '10091',\n",
       " '10092',\n",
       " '10093',\n",
       " '10094',\n",
       " '10095',\n",
       " '10096',\n",
       " '10097',\n",
       " '10098',\n",
       " '10099',\n",
       " '101',\n",
       " '1010',\n",
       " '10100',\n",
       " '10101',\n",
       " '10102',\n",
       " '10103',\n",
       " '10104',\n",
       " '10105',\n",
       " '10106',\n",
       " '10107',\n",
       " '10108',\n",
       " '10109',\n",
       " '1011',\n",
       " '10110',\n",
       " '10111',\n",
       " '10112',\n",
       " '10113',\n",
       " '10114',\n",
       " '10115',\n",
       " '10116',\n",
       " '10117',\n",
       " '10118',\n",
       " '10119',\n",
       " '1012',\n",
       " '10120',\n",
       " '10121',\n",
       " '10122',\n",
       " '10123',\n",
       " '10124',\n",
       " '10125',\n",
       " '10126',\n",
       " '10127',\n",
       " '10128',\n",
       " '10129',\n",
       " '1013',\n",
       " '10130',\n",
       " '10131',\n",
       " '10132',\n",
       " '10133',\n",
       " '10134',\n",
       " '10135',\n",
       " '10136',\n",
       " '10137',\n",
       " '10138',\n",
       " '10139',\n",
       " '1014',\n",
       " '10140',\n",
       " '10141',\n",
       " '10142',\n",
       " '10143',\n",
       " '10144',\n",
       " '10145',\n",
       " '10146',\n",
       " '10147',\n",
       " '10148',\n",
       " '10149',\n",
       " '1015',\n",
       " '10150',\n",
       " '10151',\n",
       " '10152',\n",
       " '10153',\n",
       " '10154',\n",
       " '10155',\n",
       " '10156',\n",
       " '10157',\n",
       " '10158',\n",
       " '10159',\n",
       " '1016',\n",
       " '10160',\n",
       " '10161',\n",
       " '10162',\n",
       " '10163',\n",
       " '10164',\n",
       " '10165',\n",
       " '10166',\n",
       " '10167',\n",
       " '10168',\n",
       " '10169',\n",
       " '1017',\n",
       " '10170',\n",
       " '10171',\n",
       " '10172',\n",
       " '10173',\n",
       " '10174',\n",
       " '10175',\n",
       " '10176',\n",
       " '10177',\n",
       " '10178',\n",
       " '10179',\n",
       " '1018',\n",
       " '10180',\n",
       " '10181',\n",
       " '10182',\n",
       " '10183',\n",
       " '10184',\n",
       " '10185',\n",
       " '10186',\n",
       " '10187',\n",
       " '10188',\n",
       " '10189',\n",
       " '1019',\n",
       " '10190',\n",
       " '10191',\n",
       " '10192',\n",
       " '10193',\n",
       " '10194',\n",
       " '10195',\n",
       " '10196',\n",
       " '10197',\n",
       " '10198',\n",
       " '10199',\n",
       " '102',\n",
       " '1020',\n",
       " '10200',\n",
       " '10201',\n",
       " '10202',\n",
       " '10203',\n",
       " '10204',\n",
       " '10205',\n",
       " '10206',\n",
       " '10207',\n",
       " '10208',\n",
       " '10209',\n",
       " '1021',\n",
       " '10210',\n",
       " '10211',\n",
       " '10212',\n",
       " '10213',\n",
       " '10214',\n",
       " '10215',\n",
       " '10216',\n",
       " '10217',\n",
       " '10218',\n",
       " '10219',\n",
       " '1022',\n",
       " '10220',\n",
       " '10221',\n",
       " '10222',\n",
       " '10223',\n",
       " '10224',\n",
       " '10225',\n",
       " '10226',\n",
       " '10227',\n",
       " '10228',\n",
       " '10229',\n",
       " '1023',\n",
       " '10230',\n",
       " '10231',\n",
       " '10232',\n",
       " '10233',\n",
       " '10234',\n",
       " '10235',\n",
       " '10236',\n",
       " '10237',\n",
       " '10238',\n",
       " '10239',\n",
       " '1024',\n",
       " '10240',\n",
       " '10241',\n",
       " '10242',\n",
       " '10243',\n",
       " '10244',\n",
       " '10245',\n",
       " '10246',\n",
       " '10247',\n",
       " '10248',\n",
       " '10249',\n",
       " '1025',\n",
       " '10250',\n",
       " '10251',\n",
       " '10252',\n",
       " '10253',\n",
       " '10254',\n",
       " '10255',\n",
       " '10256',\n",
       " '10257',\n",
       " '10258',\n",
       " '10259',\n",
       " '1026',\n",
       " '10260',\n",
       " '10261',\n",
       " '10262',\n",
       " '10263',\n",
       " '10264',\n",
       " '10265',\n",
       " '10266',\n",
       " '10267',\n",
       " '10268',\n",
       " '10269',\n",
       " '1027',\n",
       " '10270',\n",
       " '10271',\n",
       " '10272',\n",
       " '10273',\n",
       " '10274',\n",
       " '10275',\n",
       " '10276',\n",
       " '10277',\n",
       " '10278',\n",
       " '10279',\n",
       " '1028',\n",
       " '10280',\n",
       " '10281',\n",
       " '10282',\n",
       " '10283',\n",
       " '10284',\n",
       " '10285',\n",
       " '10286',\n",
       " '10287',\n",
       " '10288',\n",
       " '10289',\n",
       " '1029',\n",
       " '10290',\n",
       " '10291',\n",
       " '10292',\n",
       " '10293',\n",
       " '10294',\n",
       " '10295',\n",
       " '10296',\n",
       " '10297',\n",
       " '10298',\n",
       " '10299',\n",
       " '103',\n",
       " '1030',\n",
       " '10300',\n",
       " '10301',\n",
       " '10302',\n",
       " '10303',\n",
       " '10304',\n",
       " '10305',\n",
       " '10306',\n",
       " '10307',\n",
       " '10308',\n",
       " '10309',\n",
       " '1031',\n",
       " '10310',\n",
       " '10311',\n",
       " '10312',\n",
       " '10313',\n",
       " '10314',\n",
       " '10315',\n",
       " '10316',\n",
       " '10317',\n",
       " '10318',\n",
       " '10319',\n",
       " '1032',\n",
       " '10320',\n",
       " '10321',\n",
       " '10322',\n",
       " '10323',\n",
       " '10324',\n",
       " '10325',\n",
       " '10326',\n",
       " '10327',\n",
       " '10328',\n",
       " '10329',\n",
       " '1033',\n",
       " '10330',\n",
       " '10331',\n",
       " '10332',\n",
       " '10333',\n",
       " '10334',\n",
       " '10335',\n",
       " '10336',\n",
       " '10337',\n",
       " '10338',\n",
       " '10339',\n",
       " '1034',\n",
       " '10340',\n",
       " '10341',\n",
       " '10342',\n",
       " '10343',\n",
       " '10344',\n",
       " '10345',\n",
       " '10346',\n",
       " '10347',\n",
       " '10348',\n",
       " '10349',\n",
       " '1035',\n",
       " '10350',\n",
       " '10351',\n",
       " '10352',\n",
       " '10353',\n",
       " '10354',\n",
       " '10355',\n",
       " '10356',\n",
       " '10357',\n",
       " '10358',\n",
       " '10359',\n",
       " '1036',\n",
       " '10360',\n",
       " '10361',\n",
       " '10362',\n",
       " '10363',\n",
       " '10364',\n",
       " '10365',\n",
       " '10366',\n",
       " '10367',\n",
       " '10368',\n",
       " '10369',\n",
       " '1037',\n",
       " '10370',\n",
       " '10371',\n",
       " '10372',\n",
       " '10373',\n",
       " '10374',\n",
       " '10375',\n",
       " '10376',\n",
       " '10377',\n",
       " '10378',\n",
       " '10379',\n",
       " '1038',\n",
       " '10380',\n",
       " '10381',\n",
       " '10382',\n",
       " '10383',\n",
       " '10384',\n",
       " '10385',\n",
       " '10386',\n",
       " '10387',\n",
       " '10388',\n",
       " '10389',\n",
       " '1039',\n",
       " '10390',\n",
       " '10391',\n",
       " '10392',\n",
       " '10393',\n",
       " '10394',\n",
       " '10395',\n",
       " '10396',\n",
       " '10397',\n",
       " '10398',\n",
       " '10399',\n",
       " '104',\n",
       " '1040',\n",
       " '10400',\n",
       " '10401',\n",
       " '10402',\n",
       " '10403',\n",
       " '10404',\n",
       " '10405',\n",
       " '10406',\n",
       " '10407',\n",
       " '10408',\n",
       " '10409',\n",
       " '1041',\n",
       " '10410',\n",
       " '10411',\n",
       " '10412',\n",
       " '10413',\n",
       " '10414',\n",
       " '10415',\n",
       " '10416',\n",
       " '10417',\n",
       " '10418',\n",
       " '10419',\n",
       " '1042',\n",
       " '10420',\n",
       " '10421',\n",
       " '10422',\n",
       " '10423',\n",
       " '10424',\n",
       " '10425',\n",
       " '10426',\n",
       " '10427',\n",
       " '10428',\n",
       " '10429',\n",
       " '1043',\n",
       " '10430',\n",
       " '10431',\n",
       " '10432',\n",
       " '10433',\n",
       " '10434',\n",
       " '10435',\n",
       " '10436',\n",
       " '10437',\n",
       " '10438',\n",
       " '10439',\n",
       " '1044',\n",
       " '10440',\n",
       " '10441',\n",
       " '10442',\n",
       " '10443',\n",
       " '10444',\n",
       " '10445',\n",
       " '10446',\n",
       " '10447',\n",
       " '10448',\n",
       " '10449',\n",
       " '1045',\n",
       " '10450',\n",
       " '10451',\n",
       " '10452',\n",
       " '10453',\n",
       " '10454',\n",
       " '10455',\n",
       " '10456',\n",
       " '10457',\n",
       " '10458',\n",
       " '10459',\n",
       " '1046',\n",
       " '10460',\n",
       " '10461',\n",
       " '10462',\n",
       " '10463',\n",
       " '10464',\n",
       " '10465',\n",
       " '10466',\n",
       " '10467',\n",
       " '10468',\n",
       " '10469',\n",
       " '1047',\n",
       " '10470',\n",
       " '10471',\n",
       " '10472',\n",
       " '10473',\n",
       " '10474',\n",
       " '10475',\n",
       " '10476',\n",
       " '10477',\n",
       " '10478',\n",
       " '10479',\n",
       " '1048',\n",
       " '10480',\n",
       " '10481',\n",
       " '10482',\n",
       " '10483',\n",
       " '10484',\n",
       " '10485',\n",
       " '10486',\n",
       " '10487',\n",
       " '10488',\n",
       " '10489',\n",
       " '1049',\n",
       " '10490',\n",
       " '10491',\n",
       " '10492',\n",
       " '10493',\n",
       " '10494',\n",
       " '10495',\n",
       " '10496',\n",
       " '10497',\n",
       " '10498',\n",
       " '10499',\n",
       " '105',\n",
       " '1050',\n",
       " '10500',\n",
       " '10501',\n",
       " '10502',\n",
       " '10503',\n",
       " '10504',\n",
       " '10505',\n",
       " '10506',\n",
       " '10507',\n",
       " '10508',\n",
       " '10509',\n",
       " '1051',\n",
       " '10510',\n",
       " '10511',\n",
       " '10512',\n",
       " '10513',\n",
       " '10514',\n",
       " '10515',\n",
       " '10516',\n",
       " '10517',\n",
       " '10518',\n",
       " '10519',\n",
       " '1052',\n",
       " '10520',\n",
       " '10521',\n",
       " '10522',\n",
       " '10523',\n",
       " '10524',\n",
       " '10525',\n",
       " '10526',\n",
       " '10527',\n",
       " '10528',\n",
       " '10529',\n",
       " '1053',\n",
       " '10530',\n",
       " '10531',\n",
       " '10532',\n",
       " '10533',\n",
       " '10534',\n",
       " '10535',\n",
       " '10536',\n",
       " '10537',\n",
       " '10538',\n",
       " '10539',\n",
       " '1054',\n",
       " '10540',\n",
       " '10541',\n",
       " '10542',\n",
       " '10543',\n",
       " '10544',\n",
       " '10545',\n",
       " '10546',\n",
       " '10547',\n",
       " '10548',\n",
       " '10549',\n",
       " '1055',\n",
       " '10550',\n",
       " '10551',\n",
       " '10552',\n",
       " '10553',\n",
       " '10554',\n",
       " '10555',\n",
       " '10556',\n",
       " '10557',\n",
       " '10558',\n",
       " '10559',\n",
       " '1056',\n",
       " '10560',\n",
       " '10561',\n",
       " '10562',\n",
       " '10563',\n",
       " '10564',\n",
       " '10565',\n",
       " '10566',\n",
       " '10567',\n",
       " '10568',\n",
       " '10569',\n",
       " '1057',\n",
       " '10570',\n",
       " '10571',\n",
       " '10572',\n",
       " '10573',\n",
       " '10574',\n",
       " '10575',\n",
       " '10576',\n",
       " '10577',\n",
       " '10578',\n",
       " '10579',\n",
       " '1058',\n",
       " '10580',\n",
       " '10581',\n",
       " '10582',\n",
       " '10583',\n",
       " '10584',\n",
       " '10585',\n",
       " '10586',\n",
       " '10587',\n",
       " '10588',\n",
       " '10589',\n",
       " '1059',\n",
       " '10590',\n",
       " '10591',\n",
       " '10592',\n",
       " '10593',\n",
       " '10594',\n",
       " '10595',\n",
       " '10596',\n",
       " '10597',\n",
       " '10598',\n",
       " '10599',\n",
       " '106',\n",
       " '1060',\n",
       " '10600',\n",
       " '10601',\n",
       " '10602',\n",
       " '10603',\n",
       " '10604',\n",
       " '10605',\n",
       " '10606',\n",
       " '10607',\n",
       " '10608',\n",
       " '10609',\n",
       " '1061',\n",
       " '10610',\n",
       " '10611',\n",
       " '10612',\n",
       " '10613',\n",
       " '10614',\n",
       " '10615',\n",
       " '10616',\n",
       " '10617',\n",
       " '10618',\n",
       " '10619',\n",
       " '1062',\n",
       " '10620',\n",
       " '10621',\n",
       " '10622',\n",
       " '10623',\n",
       " '10624',\n",
       " '10625',\n",
       " '10626',\n",
       " '10627',\n",
       " '10628',\n",
       " '10629',\n",
       " '1063',\n",
       " '10630',\n",
       " '10631',\n",
       " '10632',\n",
       " '10633',\n",
       " '10634',\n",
       " '10635',\n",
       " '10636',\n",
       " '10637',\n",
       " '10638',\n",
       " '10639',\n",
       " '1064',\n",
       " '10640',\n",
       " '10641',\n",
       " '10642',\n",
       " '10643',\n",
       " '10644',\n",
       " '10645',\n",
       " '10646',\n",
       " '10647',\n",
       " '10648',\n",
       " '10649',\n",
       " '1065',\n",
       " '10650',\n",
       " '10651',\n",
       " '10652',\n",
       " '10653',\n",
       " '10654',\n",
       " '10655',\n",
       " '10656',\n",
       " '10657',\n",
       " '10658',\n",
       " '10659',\n",
       " '1066',\n",
       " '10660',\n",
       " '10661',\n",
       " '10662',\n",
       " '10663',\n",
       " '10664',\n",
       " '10665',\n",
       " '10666',\n",
       " '10667',\n",
       " '10668',\n",
       " '10669',\n",
       " '1067',\n",
       " '10670',\n",
       " '10671',\n",
       " '10672',\n",
       " '10673',\n",
       " '10674',\n",
       " '10675',\n",
       " '10676',\n",
       " '10677',\n",
       " '10678',\n",
       " '10679',\n",
       " '1068',\n",
       " '10680',\n",
       " '10681',\n",
       " '10682',\n",
       " '10683',\n",
       " '10684',\n",
       " '10685',\n",
       " '10686',\n",
       " '10687',\n",
       " '10688',\n",
       " '10689',\n",
       " '1069',\n",
       " '10690',\n",
       " '10691',\n",
       " '10692',\n",
       " '10693',\n",
       " '10694',\n",
       " '10695',\n",
       " '10696',\n",
       " '10697',\n",
       " '10698',\n",
       " '10699',\n",
       " '107',\n",
       " '1070',\n",
       " '10700',\n",
       " '10701',\n",
       " '10702',\n",
       " '10703',\n",
       " '10704',\n",
       " '10705',\n",
       " '10706',\n",
       " '10707',\n",
       " '10708',\n",
       " '10709',\n",
       " '1071',\n",
       " '10710',\n",
       " '10711',\n",
       " '10712',\n",
       " '10713',\n",
       " '10714',\n",
       " '10715',\n",
       " '10716',\n",
       " '10717',\n",
       " '10718',\n",
       " '10719',\n",
       " '1072',\n",
       " '10720',\n",
       " '10721',\n",
       " '10722',\n",
       " '10723',\n",
       " '10724',\n",
       " '10725',\n",
       " '10726',\n",
       " '10727',\n",
       " '10728',\n",
       " '10729',\n",
       " '1073',\n",
       " '10730',\n",
       " '10731',\n",
       " '10732',\n",
       " '10733',\n",
       " '10734',\n",
       " '10735',\n",
       " '10736',\n",
       " '10737',\n",
       " '10738',\n",
       " '10739',\n",
       " '1074',\n",
       " '10740',\n",
       " '10741',\n",
       " '10742',\n",
       " '10743',\n",
       " '10744',\n",
       " '10745',\n",
       " '10746',\n",
       " '10747',\n",
       " '10748',\n",
       " '10749',\n",
       " '1075',\n",
       " '10750',\n",
       " '10751',\n",
       " '10752',\n",
       " '10753',\n",
       " '10754',\n",
       " '10755',\n",
       " '10756',\n",
       " '10757',\n",
       " '10758',\n",
       " '10759',\n",
       " '1076',\n",
       " '10760',\n",
       " '10761',\n",
       " '10762',\n",
       " '10763',\n",
       " '10764',\n",
       " '10765',\n",
       " '10766',\n",
       " '10767',\n",
       " '10768',\n",
       " '10769',\n",
       " '1077',\n",
       " '10770',\n",
       " '10771',\n",
       " '10772',\n",
       " '10773',\n",
       " '10774',\n",
       " '10775',\n",
       " '10776',\n",
       " '10777',\n",
       " '10778',\n",
       " '10779',\n",
       " '1078',\n",
       " '10780',\n",
       " '10781',\n",
       " '10782',\n",
       " '10783',\n",
       " '10784',\n",
       " '10785',\n",
       " '10786',\n",
       " '10787',\n",
       " '10788',\n",
       " '10789',\n",
       " '1079',\n",
       " '10790',\n",
       " '10791',\n",
       " '10792',\n",
       " '10793',\n",
       " '10794',\n",
       " '10795',\n",
       " '10796',\n",
       " '10797',\n",
       " '10798',\n",
       " '10799',\n",
       " '108',\n",
       " '1080',\n",
       " '10800',\n",
       " '10801',\n",
       " '10802',\n",
       " '10803',\n",
       " '10804',\n",
       " '10805',\n",
       " '10806',\n",
       " '10807',\n",
       " '10808',\n",
       " '10809',\n",
       " '1081',\n",
       " '10810',\n",
       " '10811',\n",
       " '10812',\n",
       " '10813',\n",
       " '10814',\n",
       " '10815',\n",
       " '10816',\n",
       " '10817',\n",
       " '10818',\n",
       " '10819',\n",
       " '1082',\n",
       " '10820',\n",
       " '10821',\n",
       " '10822',\n",
       " '10823',\n",
       " '10824',\n",
       " '10825',\n",
       " '10826',\n",
       " '10827',\n",
       " '10828',\n",
       " '10829',\n",
       " '1083',\n",
       " '10830',\n",
       " '10831',\n",
       " '10832',\n",
       " '10833',\n",
       " '10834',\n",
       " '10835',\n",
       " '10836',\n",
       " '10837',\n",
       " '10838',\n",
       " '10839',\n",
       " '1084',\n",
       " '10840',\n",
       " '10841',\n",
       " '10842',\n",
       " '10843',\n",
       " '10844',\n",
       " '10845',\n",
       " '10846',\n",
       " '10847',\n",
       " '10848',\n",
       " '10849',\n",
       " '1085',\n",
       " '10850',\n",
       " '10851',\n",
       " '10852',\n",
       " '10853',\n",
       " '10854',\n",
       " '10855',\n",
       " '10856',\n",
       " '10857',\n",
       " '10858',\n",
       " '10859',\n",
       " '1086',\n",
       " '10860',\n",
       " '10861',\n",
       " '10862',\n",
       " '10863',\n",
       " '10864',\n",
       " '10865',\n",
       " '10866',\n",
       " '10867',\n",
       " '10868',\n",
       " '10869',\n",
       " '1087',\n",
       " '10870',\n",
       " '10871',\n",
       " '10872',\n",
       " '10873',\n",
       " '10874',\n",
       " '10875',\n",
       " '10876',\n",
       " '10877',\n",
       " '10878',\n",
       " '10879',\n",
       " '1088',\n",
       " '10880',\n",
       " '10881',\n",
       " '10882',\n",
       " '10883',\n",
       " '10884',\n",
       " '10885',\n",
       " '10886',\n",
       " '10887',\n",
       " '10888',\n",
       " '10889',\n",
       " '1089',\n",
       " '10890',\n",
       " '10891',\n",
       " '10892',\n",
       " '10893',\n",
       " '10894',\n",
       " '10895',\n",
       " '10896',\n",
       " '10897',\n",
       " '10898',\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fake_model.load_weights('models/dogscats_ft_preprocessed2.h5')\n",
    "test_batches = gen.flow_from_directory(path+'/test', target_size=(224,224), class_mode='categorical', shuffle=False, batch_size=20)\n",
    "test_steps = int(np.ceil(test_batches.samples/batch_size))\n",
    "ids = []\n",
    "for filename in test_batches.filenames:\n",
    "    ids.append(filename.split('/')[1].split('.')[0])\n",
    "preds = fake_model.predict_generator(test_batches, test_steps)\n",
    "#ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10002</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10003</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10004</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10005</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10006</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10007</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10008</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10009</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10010</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10011</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10012</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10013</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10014</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10015</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10016</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10017</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10018</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10019</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1002</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10020</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10021</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10022</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10023</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12470</th>\n",
       "      <td>9972</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12471</th>\n",
       "      <td>9973</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12472</th>\n",
       "      <td>9974</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12473</th>\n",
       "      <td>9975</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12474</th>\n",
       "      <td>9976</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12475</th>\n",
       "      <td>9977</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12476</th>\n",
       "      <td>9978</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12477</th>\n",
       "      <td>9979</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12478</th>\n",
       "      <td>998</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12479</th>\n",
       "      <td>9980</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12480</th>\n",
       "      <td>9981</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12481</th>\n",
       "      <td>9982</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12482</th>\n",
       "      <td>9983</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12483</th>\n",
       "      <td>9984</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12484</th>\n",
       "      <td>9985</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12485</th>\n",
       "      <td>9986</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>9987</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12487</th>\n",
       "      <td>9988</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>9989</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12489</th>\n",
       "      <td>999</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12490</th>\n",
       "      <td>9990</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12491</th>\n",
       "      <td>9991</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12492</th>\n",
       "      <td>9992</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12493</th>\n",
       "      <td>9993</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12494</th>\n",
       "      <td>9994</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>9995</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>9996</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>9997</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>9998</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>9999</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label\n",
       "0          1   0.95\n",
       "1         10   0.05\n",
       "2        100   0.05\n",
       "3       1000   0.95\n",
       "4      10000   0.95\n",
       "5      10001   0.05\n",
       "6      10002   0.05\n",
       "7      10003   0.95\n",
       "8      10004   0.95\n",
       "9      10005   0.05\n",
       "10     10006   0.05\n",
       "11     10007   0.05\n",
       "12     10008   0.05\n",
       "13     10009   0.05\n",
       "14      1001   0.05\n",
       "15     10010   0.95\n",
       "16     10011   0.95\n",
       "17     10012   0.05\n",
       "18     10013   0.05\n",
       "19     10014   0.05\n",
       "20     10015   0.95\n",
       "21     10016   0.05\n",
       "22     10017   0.05\n",
       "23     10018   0.05\n",
       "24     10019   0.05\n",
       "25      1002   0.95\n",
       "26     10020   0.05\n",
       "27     10021   0.05\n",
       "28     10022   0.95\n",
       "29     10023   0.95\n",
       "...      ...    ...\n",
       "12470   9972   0.05\n",
       "12471   9973   0.95\n",
       "12472   9974   0.05\n",
       "12473   9975   0.05\n",
       "12474   9976   0.95\n",
       "12475   9977   0.05\n",
       "12476   9978   0.05\n",
       "12477   9979   0.05\n",
       "12478    998   0.95\n",
       "12479   9980   0.05\n",
       "12480   9981   0.05\n",
       "12481   9982   0.95\n",
       "12482   9983   0.05\n",
       "12483   9984   0.95\n",
       "12484   9985   0.95\n",
       "12485   9986   0.95\n",
       "12486   9987   0.95\n",
       "12487   9988   0.95\n",
       "12488   9989   0.95\n",
       "12489    999   0.05\n",
       "12490   9990   0.95\n",
       "12491   9991   0.95\n",
       "12492   9992   0.95\n",
       "12493   9993   0.05\n",
       "12494   9994   0.05\n",
       "12495   9995   0.05\n",
       "12496   9996   0.95\n",
       "12497   9997   0.95\n",
       "12498   9998   0.05\n",
       "12499   9999   0.05\n",
       "\n",
       "[12500 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['id'] = ids\n",
    "df['label'] = np.clip(preds[:, 1], 0.05, 0.95)\n",
    "df[['id', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('dogscats_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
